{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Semantic segmentation of intergranular fractions from image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for processing image data we use fastai.vision\n",
    "from fastai.vision.all import * \n",
    "# At the latest, we should definitely use the GPU for computing. Therefore, the very first thing we test is,\n",
    "# if we have a kind CUDA device available\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed fixieren -> pseudo zufällig \n",
    "torch.manual_seed(0) # für pyTorch\n",
    "random.seed(0)       # für python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we get problems with occupied memory on the GPU. In these cases it can help to run the garbage collection. Alternatively, the entire Jupyter server can be restarted, which works more reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path = Path('./data/intergranular_crack/64')\n",
    "\n",
    "# Um höhere Auflösungen zu testen, kann dies hier geändert werden:\n",
    "# path = Path('./data/intergranular_crack/256')\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create two paths, one for images and one for masks (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = path/'images'\n",
    "path_labels = path/'mask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get overview of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the naming of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = get_image_files(path_images)\n",
    "file_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how the corresponding label files are names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = get_image_files(path_labels)\n",
    "label_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since image names and label names do not differ, we only need to map folders to each other to get the corresponding mask for an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_function(filename):\n",
    "    return path_labels / Path(filename.stem + filename.suffix )\n",
    "\n",
    "# Often label functions are also written using lambda expressions. The label function above could be expressed as\n",
    "# following as a lambda expression:\n",
    "# get_y_fn = lambda x: path_labels/f'{x.stem}{x.suffix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first test whether the paths match each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( file_names[0] )\n",
    "print( label_function(file_names[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of this function we can display the corresponding label image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "image = load_image(file_names[3])\n",
    "mask = load_image(label_function(file_names[3]))\n",
    "mask2 = load_image(label_function(file_names[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we'll look at how to display labels, in this case images that contain only values 0 and 1. \n",
    "# can be displayed in a way that is visually clear. This takes us away from the core of this exercise, but is\n",
    "# but very useful\n",
    "\n",
    "# We will create a custom ColorMap, which will result in our masks being displayed in a colorful way.\n",
    "import matplotlib as mp\n",
    "cpts = [0.0, 254.0/255.0, 1.0]\n",
    "colors = [(cpts[0], (0, 0, 0)), (cpts[1], (.5, .5, .5)), (cpts[2], (1, 0, 0))]\n",
    "cmap_name = 'my_list'\n",
    "colormap = mp.colors.LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "\n",
    "# The following example shows how to use matplotlib.pyplot to create graphs with \n",
    "# multiple parts. For this task it is not necessarily\n",
    "# necessary to inspect data after loading, but is definitely # advisable.\n",
    "# advisable\n",
    "figure = plt.figure( figsize=(8,4))\n",
    "axis = figure.add_subplot(1, 2, 1)\n",
    "axis.set_title('Bild')\n",
    "plt.imshow(image)\n",
    "plt.colorbar()\n",
    "axis = figure.add_subplot(1, 2, 2)\n",
    "axis.set_title('Mask')\n",
    "display_mask = numpy.asarray(mask) \n",
    "plt.imshow(display_mask, cmap=colormap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way we check what is stored in the label image and if it was loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to map the pixel values to a class, we still need to specify the appropriate mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( mask.getextrema() )\n",
    "codes = np.array(['background','crack'])\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a SegmentationDataLoaders that loads the appropriate output (labels) for each image using a label_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablocks = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "                       get_items = get_image_files,\n",
    "                       get_y = label_function,\n",
    "                       splitter=RandomSplitter(seed=42))\n",
    "\n",
    "data_loader = datablocks.dataloaders(path_images, bs=4, num_workers=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to our classification example, we output a minibatch for control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.show_batch( max_n=4, vmin=0, vmax=1, cmap=colormap )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to adapt the used metric to our segmentation problem. For a better understanding, let's first look at the original version of Accuracy (original_accuracy) because the code is not easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import TensorBase\n",
    "\n",
    "# Input is:\n",
    "# Predictions in hot-1-encoding, format batchsize x n_classes x x_size x y_size, z.B. 4x2x128x128\n",
    "# Target                         format batchsize x x_size x y_size,             z.B. 4x128x128\n",
    "def original_accuracy(predictions, target):\n",
    "    # Zunächst machen wir das hot-1-encoding von Predictions rückgängig, indem wir die Indices der höchsten Werte bestimmen\n",
    "    pred_hot1_decoded = predictions.argmax(dim=1)\n",
    "    # Then we store in a vector in each case \"True\" if Prediction and Target agree, \"False\" if not.\n",
    "    # Here it is to be noted that the operator == stands for a comparison. Applied to a vector it returns\n",
    "    # a vector back over \"True\" where the two values match. \n",
    "    # The operator = stands for an assignment and should not be confused with the comparison (==).\n",
    "    correct_predictions = ( TensorBase(pred_hot1_decoded) == TensorBase(target) )\n",
    "    # We convert this vector to float, this way \"True\" becomes 1.0, \"False\" becomes 0.0\n",
    "    correct_predictions = correct_predictions.float()\n",
    "    # The mean value then indicates exactly how high the proportion of correct predictions is\n",
    "    return correct_predictions.mean()\n",
    "\n",
    "def accuracy_crack(predictions, target):   \n",
    "    # implement the accuracy crack which is computing accuracy only for the crack class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [accuracy_crack, original_accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For segmentation we use `U-NET`, which is practically already available in the form of `unet_learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as torchModels\n",
    "\n",
    "# learner = unet_learner(data_loader, torchModels.vgg16, metrics = metrics)\n",
    "# implement your own U-Net model here\n",
    "\n",
    "learner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empties available GPU memory via garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"unet_initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gewaehlteLernrate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load(\"unet_initial\")\n",
    "learner.fit_one_cycle(5, slice(gewaehlteLernrate), cbs=[ShowGraphCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learner.get_preds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.show_results( figsize=(12,10), vmin=0, vmax=1, cmap=colormap )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
